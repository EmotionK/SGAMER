nohup: ignoring input
run.py device: cuda
----------------------------------------------------------------------------------------------------
Amazon_Musical_Instruments......
----------------------------------------------------------------------------------------------------
/home/ubuntu/model/PaperModel/model/../model/util/data_utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  nodewv_tensor = torch.Tensor(nodewv_tensor)
labels.shape: torch.Size([585800])
loading node embedding, all user-item and item-item paths embedding...finished
start training user-item instance self attention module...
user  0 time:  9.059906005859375e-06
user  100 time:  210.39035177230835
user  200 time:  421.002587556839
user  300 time:  636.4100615978241
user  400 time:  842.9056117534637
user  500 time:  1056.673061132431
user  600 time:  1275.2103838920593
user  700 time:  1496.3120465278625
user  800 time:  1717.1493332386017
user  900 time:  1938.3417389392853
user  1000 time:  2159.2163491249084
user  1100 time:  2381.293320417404
user  1200 time:  2602.1820113658905
user  1300 time:  2823.5001680850983
user  1400 time:  3045.4567046165466
start training item-item instance self attention module...
user  0 time:  7.867813110351562e-06
user  100 time:  175.6499526500702
user  200 time:  339.91580152511597
user  300 time:  523.4474847316742
user  400 time:  692.8708157539368
user  500 time:  859.8096017837524
user  600 time:  1040.1122860908508
user  700 time:  1211.0914261341095
user  800 time:  1388.8124520778656
user  900 time:  1558.3015656471252
user  1000 time:  1733.59960603714
user  1100 time:  1915.2688064575195
user  1200 time:  2088.453577041626
user  1300 time:  2275.591677427292
user  1400 time:  2472.7946734428406
start updating user and item embedding...
user_name:1450
user  0 time:  1.430511474609375e-05
user  100 time:  80.31640958786011
user  200 time:  160.51788473129272
user  300 time:  241.22820496559143
user  400 time:  322.3573124408722
user  500 time:  403.0090777873993
user  600 time:  484.0804009437561
user  700 time:  571.3847584724426
user  800 time:  662.4091002941132
user  900 time:  754.691703081131
user  1000 time:  846.747236251831
user  1100 time:  938.4842851161957
user  1200 time:  1030.4581608772278
user  1300 time:  1122.0988733768463
user  1400 time:  1214.53440451622
start training recommendation module...
/home/ubuntu/model/PaperModel/model/recommendation_model.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  fe = F.log_softmax(output)
epoch: 0, training loss: 148.09344146039803, train time: 64.43649768829346
epoch: 1, training loss: 87.90005566790933, train time: 63.46770358085632
epoch: 2, training loss: 73.98940877271525, train time: 63.55052161216736
epoch: 3, training loss: 66.3323016369759, train time: 63.132508993148804
epoch: 4, training loss: 61.0579465150804, train time: 65.76078772544861
epoch: 5, training loss: 57.3843510747829, train time: 63.457064151763916
epoch: 6, training loss: 53.53402617441316, train time: 63.418280601501465
epoch: 7, training loss: 50.54261387783481, train time: 63.32585287094116
epoch: 8, training loss: 48.21943627568544, train time: 63.47059154510498
epoch: 9, training loss: 45.77100182295544, train time: 63.19927978515625
epoch: 10, training loss: 43.58634567793342, train time: 63.37797689437866
epoch: 11, training loss: 41.568452836618235, train time: 65.31804585456848
epoch: 12, training loss: 39.88157285706984, train time: 74.6052656173706
epoch: 13, training loss: 38.27011582723935, train time: 74.47928023338318
epoch: 14, training loss: 36.75335986682694, train time: 74.58355045318604
epoch: 15, training loss: 35.0714345848246, train time: 74.69406628608704
epoch: 16, training loss: 33.26354127134255, train time: 74.7920913696289
epoch: 17, training loss: 32.09790960604005, train time: 69.10265231132507
epoch: 18, training loss: 30.482435900263226, train time: 63.47162079811096
epoch: 19, training loss: 28.390322272631238, train time: 63.94633483886719
epoch: 20, training loss: 27.409361829486443, train time: 63.29327082633972
epoch: 21, training loss: 25.800571883090015, train time: 73.85781168937683
epoch: 22, training loss: 24.585903761271766, train time: 77.80939888954163
epoch: 23, training loss: 23.190132386465848, train time: 77.86950993537903
epoch: 24, training loss: 22.678706915075963, train time: 77.61192083358765
epoch: 25, training loss: 21.661339921754916, train time: 77.58194851875305
epoch: 26, training loss: 21.359700377913214, train time: 84.46170139312744
epoch: 27, training loss: 20.68150433307983, train time: 89.58863115310669
epoch: 28, training loss: 19.209605999194537, train time: 89.77050185203552
epoch: 29, training loss: 19.15283918550267, train time: 89.83075666427612
保存hit模型
保存ndcg模型
epo:29 | HR@5:0.7955 | HR@10:0.8356 | HR@20:0.8852 | NDCG@5:0.4445 | NDCG@10:0.4834 | NDCG@20:0.5340 | best_HR@5:0.7955 | best_HR@10:0.8356 | best_HR@20:0.8852 | best_NDCG@5:0.4445 | best_NDCG@10:0.4834 | best_NDCG@20:0.5340 | 
epoch: 30, training loss: 17.780911287058643, train time: 89.87933039665222
epoch: 31, training loss: 17.316217614895322, train time: 89.66855359077454
epoch: 32, training loss: 17.328639977575676, train time: 90.26831722259521
epoch: 33, training loss: 16.358370817712967, train time: 89.73604416847229
epoch: 34, training loss: 16.707414010891625, train time: 80.20589828491211
epoch: 35, training loss: 16.565660557702813, train time: 77.5879716873169
epoch: 36, training loss: 15.580058637223374, train time: 77.7547996044159
epoch: 37, training loss: 16.203520559130084, train time: 77.68560242652893
epoch: 38, training loss: 15.085930652194747, train time: 77.65794897079468
epoch: 39, training loss: 15.133784745513367, train time: 77.60797643661499
epoch: 40, training loss: 13.784849740435902, train time: 77.73366236686707
epoch: 41, training loss: 14.073213753913706, train time: 79.79468393325806
epoch: 42, training loss: 14.49315879292908, train time: 89.89549493789673
epoch: 43, training loss: 13.843970180030055, train time: 86.58166980743408
epoch: 44, training loss: 15.369609992764026, train time: 77.75677275657654
epoch: 45, training loss: 13.00184437148664, train time: 77.46884775161743
epoch: 46, training loss: 13.843812695505221, train time: 77.7275037765503
epoch: 47, training loss: 13.330782183892211, train time: 77.86667227745056
epoch: 48, training loss: 13.240754032774703, train time: 74.78176808357239
epoch: 49, training loss: 13.291108668256584, train time: 64.91507649421692
epoch: 50, training loss: 11.914069538471267, train time: 64.63226437568665
epoch: 51, training loss: 13.079353840183217, train time: 65.69238710403442
epoch: 52, training loss: 12.380445774907287, train time: 64.82236099243164
epoch: 53, training loss: 12.054525749357936, train time: 77.44722938537598
epoch: 54, training loss: 12.44704549604296, train time: 77.77507996559143
epoch: 55, training loss: 12.12987676388559, train time: 77.71179962158203
epoch: 56, training loss: 12.13861090025216, train time: 77.4686770439148
epoch: 57, training loss: 12.328614921944109, train time: 81.31553530693054
epoch: 58, training loss: 11.459332953232888, train time: 90.57492756843567
epoch: 59, training loss: 12.243690985741182, train time: 89.72778677940369
保存ndcg模型
epo:59 | HR@5:0.7745 | HR@10:0.8170 | HR@20:0.8647 | NDCG@5:0.4742 | NDCG@10:0.5101 | NDCG@20:0.5571 | best_HR@5:0.7955 | best_HR@10:0.8356 | best_HR@20:0.8852 | best_NDCG@5:0.4742 | best_NDCG@10:0.5101 | best_NDCG@20:0.5571 | 
epoch: 60, training loss: 10.896778214186952, train time: 89.54516673088074
epoch: 61, training loss: 12.08831510198877, train time: 89.95449614524841
epoch: 62, training loss: 11.414243430301894, train time: 89.55309224128723
epoch: 63, training loss: 11.93166078760737, train time: 89.7656991481781
epoch: 64, training loss: 11.454384142931644, train time: 80.76440715789795
epoch: 65, training loss: 10.01013330436831, train time: 77.60100793838501
epoch: 66, training loss: 12.499079271702158, train time: 77.70091462135315
epoch: 67, training loss: 11.26557451622648, train time: 77.45079445838928
epoch: 68, training loss: 11.369752470941137, train time: 77.95844912528992
epoch: 69, training loss: 11.631275506650582, train time: 77.40532946586609
epoch: 70, training loss: 10.185066916272035, train time: 77.84362602233887
epoch: 71, training loss: 11.93196975964429, train time: 79.99686431884766
epoch: 72, training loss: 9.594486954461786, train time: 89.82619071006775
epoch: 73, training loss: 11.74928645100789, train time: 89.46802091598511
epoch: 74, training loss: 9.83386381847697, train time: 89.8593852519989
epoch: 75, training loss: 11.30300328682597, train time: 83.52836585044861
epoch: 76, training loss: 10.461727665737214, train time: 78.42568850517273
epoch: 77, training loss: 9.540975659826273, train time: 77.5077772140503
epoch: 78, training loss: 10.393620819107468, train time: 77.8760256767273
epoch: 79, training loss: 11.107706020210344, train time: 78.0472617149353
epoch: 80, training loss: 10.292714498828559, train time: 69.47156763076782
epoch: 81, training loss: 10.058801183167475, train time: 67.02412724494934
epoch: 82, training loss: 10.16907044609377, train time: 64.73839235305786
epoch: 83, training loss: 9.93333339613389, train time: 64.76099252700806
epoch: 84, training loss: 10.639624689658945, train time: 67.2904703617096
epoch: 85, training loss: 8.773816898634664, train time: 77.66291642189026
epoch: 86, training loss: 9.37401020067648, train time: 77.88337063789368
epoch: 87, training loss: 10.615487715219956, train time: 77.62010884284973
epoch: 88, training loss: 9.578169850293136, train time: 77.7079553604126
epoch: 89, training loss: 9.846318169836536, train time: 82.68969869613647
epo:89 | HR@5:0.7397 | HR@10:0.7829 | HR@20:0.8336 | NDCG@5:0.4717 | NDCG@10:0.5084 | NDCG@20:0.5558 | best_HR@5:0.7955 | best_HR@10:0.8356 | best_HR@20:0.8852 | best_NDCG@5:0.4742 | best_NDCG@10:0.5101 | best_NDCG@20:0.5571 | 
epoch: 90, training loss: 9.649249865088223, train time: 89.65975499153137
epoch: 91, training loss: 9.565659945659888, train time: 89.48858213424683
epoch: 92, training loss: 8.972157449390068, train time: 89.9595832824707
epoch: 93, training loss: 9.97998301444585, train time: 89.92318034172058
epoch: 94, training loss: 8.78811953235396, train time: 80.72496199607849
epoch: 95, training loss: 10.936999501798823, train time: 77.6626923084259
epoch: 96, training loss: 9.073636609641767, train time: 77.94083380699158
epoch: 97, training loss: 9.177456383062292, train time: 78.56510376930237
epoch: 98, training loss: 9.01784931970596, train time: 77.88668179512024
epoch: 99, training loss: 9.32865233026439, train time: 77.41422629356384
epoch: 100, training loss: 9.788885314472395, train time: 78.18014025688171
epoch: 101, training loss: 9.06122184531057, train time: 80.31032919883728
epoch: 102, training loss: 10.13040787846171, train time: 89.34800219535828
epoch: 103, training loss: 9.620143606971226, train time: 89.58622622489929
epoch: 104, training loss: 9.82324601817794, train time: 89.81552147865295
epoch: 105, training loss: 7.439714803761717, train time: 89.5931408405304
epoch: 106, training loss: 9.100344707186537, train time: 89.31799936294556
epoch: 107, training loss: 9.28677573312467, train time: 80.86249899864197
epoch: 108, training loss: 9.11494412813147, train time: 77.67316269874573
epoch: 109, training loss: 9.21145670035412, train time: 77.7316381931305
epoch: 110, training loss: 8.850771975623275, train time: 77.82839918136597
epoch: 111, training loss: 7.878382327590543, train time: 76.90743350982666
epoch: 112, training loss: 8.636294019435013, train time: 64.72474956512451
epoch: 113, training loss: 9.188499755762564, train time: 67.72384858131409
epoch: 114, training loss: 8.67155327584743, train time: 66.08140563964844
epoch: 115, training loss: 8.726220253715752, train time: 65.21867156028748
epoch: 116, training loss: 9.347313485404413, train time: 68.66097521781921
epoch: 117, training loss: 8.869732942622932, train time: 77.71106219291687
epoch: 118, training loss: 7.754502975116964, train time: 77.67385506629944
epoch: 119, training loss: 8.895061018220389, train time: 77.76291584968567
epo:119 | HR@5:0.7551 | HR@10:0.7953 | HR@20:0.8426 | NDCG@5:0.4701 | NDCG@10:0.5078 | NDCG@20:0.5559 | best_HR@5:0.7955 | best_HR@10:0.8356 | best_HR@20:0.8852 | best_NDCG@5:0.4742 | best_NDCG@10:0.5101 | best_NDCG@20:0.5571 | 
epoch: 120, training loss: 8.988687305020107, train time: 90.06712770462036
epoch: 121, training loss: 9.123600094573874, train time: 90.11203670501709
epoch: 122, training loss: 8.992972764226721, train time: 89.59831190109253
epoch: 123, training loss: 7.887867210043396, train time: 85.43496203422546
epoch: 124, training loss: 7.798368428607944, train time: 78.09575343132019
epoch: 125, training loss: 8.959643364592495, train time: 77.55002951622009
epoch: 126, training loss: 7.876093840085218, train time: 77.78962087631226
epoch: 127, training loss: 8.315056312682941, train time: 78.05411434173584
epoch: 128, training loss: 8.784726537190622, train time: 79.04033708572388
epoch: 129, training loss: 9.030134556221356, train time: 77.68982481956482
epoch: 130, training loss: 7.536575645091716, train time: 77.6898877620697
epoch: 131, training loss: 7.96568869244777, train time: 70.45208239555359
epoch: 132, training loss: 7.757933151113491, train time: 69.04587841033936
epoch: 133, training loss: 7.987168895738648, train time: 69.36568212509155
epoch: 134, training loss: 8.407048198965867, train time: 69.03380465507507
epoch: 135, training loss: 7.910073826908132, train time: 69.16784501075745
epoch: 136, training loss: 8.291745146857465, train time: 69.2315444946289
epoch: 137, training loss: 8.148194612218845, train time: 69.20502710342407
epoch: 138, training loss: 8.429577457555268, train time: 62.38182091712952
epoch: 139, training loss: 7.961593289328107, train time: 55.09605383872986
epoch: 140, training loss: 7.935345960568611, train time: 64.03631567955017
epoch: 141, training loss: 8.996234968959271, train time: 56.57796931266785
epoch: 142, training loss: 7.633532791172826, train time: 56.364638328552246
epoch: 143, training loss: 7.687537443094811, train time: 56.82870602607727
epoch: 144, training loss: 8.476292810781644, train time: 44.579864501953125
epoch: 145, training loss: 8.750299578996362, train time: 48.10681200027466
epoch: 146, training loss: 7.438206159004352, train time: 50.869362592697144
epoch: 147, training loss: 7.615523202946804, train time: 42.22478008270264
epoch: 148, training loss: 7.396105669179974, train time: 41.43852496147156
epoch: 149, training loss: 8.277741069721685, train time: 41.912866830825806
保存ndcg模型
epo:149 | HR@5:0.7297 | HR@10:0.7732 | HR@20:0.8251 | NDCG@5:0.4788 | NDCG@10:0.5147 | NDCG@20:0.5618 | best_HR@5:0.7955 | best_HR@10:0.8356 | best_HR@20:0.8852 | best_NDCG@5:0.4788 | best_NDCG@10:0.5147 | best_NDCG@20:0.5618 | 
training finish
