nohup: ignoring input
run.py device: cuda
/home/ubuntu/model/PaperModel/model/../model/util/data_utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  nodewv_tensor = torch.Tensor(nodewv_tensor)
/home/ubuntu/miniconda3/envs/PaperModel/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
labels.shape: torch.Size([2905800])
loading node embedding, all user-item and item-item paths embedding...finished
start training user-item instance self attention module...
user  0 time:  4.76837158203125e-06
user  100 time:  15.148930311203003
user  200 time:  27.62465810775757
user  300 time:  38.98980164527893
user  400 time:  52.451244592666626
user  500 time:  65.49793529510498
user  600 time:  71.03758382797241
user  700 time:  82.11707925796509
user  800 time:  90.68276405334473
user  900 time:  103.71289896965027
user  1000 time:  118.3058066368103
user  1100 time:  132.3905098438263
user  1200 time:  142.4365735054016
user  1300 time:  153.74539709091187
user  1400 time:  162.3648202419281
start training item-item instance self attention module...
user  0 time:  1.2636184692382812e-05
user  100 time:  193.05513834953308
user  200 time:  388.3464593887329
user  300 time:  577.7860972881317
user  400 time:  771.3901333808899
user  500 time:  957.136378288269
user  600 time:  1154.8212504386902
user  700 time:  1346.1849157810211
user  800 time:  1540.3638603687286
user  900 time:  1730.8551619052887
user  1000 time:  1915.38303399086
user  1100 time:  2107.962769985199
user  1200 time:  2304.931789159775
user  1300 time:  2498.152450799942
user  1400 time:  2691.507739305496
start updating user and item embedding...
user_name:1450
user  0 time:  1.33514404296875e-05
user  100 time:  16.38131046295166
user  200 time:  32.67912697792053
user  300 time:  49.06822896003723
user  400 time:  65.49684762954712
user  500 time:  81.7643575668335
user  600 time:  98.496089220047
user  700 time:  114.90557599067688
user  800 time:  131.33307552337646
user  900 time:  147.54990220069885
user  1000 time:  163.8522126674652
user  1100 time:  180.28876495361328
user  1200 time:  196.68508911132812
user  1300 time:  212.9819095134735
user  1400 time:  229.19098830223083
start training recommendation module...
/home/ubuntu/model/PaperModel/model/recommendation_model.py:54: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  fe = F.log_softmax(output)
epoch: 0, training loss: 426.73255486862035, train time: 114.36692881584167
epoch: 1, training loss: 418.8572801950213, train time: 114.73357152938843
epoch: 2, training loss: 418.2820170826162, train time: 114.18302273750305
epoch: 3, training loss: 417.27142902929336, train time: 115.18390440940857
epoch: 4, training loss: 416.51005181198707, train time: 114.21453094482422
epoch: 5, training loss: 416.7151799777057, train time: 113.22021293640137
epoch: 6, training loss: 416.8086415033031, train time: 112.31361961364746
epoch: 7, training loss: 417.1750773075328, train time: 112.5442111492157
epoch: 8, training loss: 417.01511841846514, train time: 112.90558743476868
epoch: 9, training loss: 415.79046935224324, train time: 114.67659735679626
epoch: 10, training loss: 416.3821949213161, train time: 114.09877490997314
epoch: 11, training loss: 417.05768118583364, train time: 113.18403172492981
epoch: 12, training loss: 416.1689874815347, train time: 113.06375408172607
epoch: 13, training loss: 416.49072488423553, train time: 110.59375596046448
epoch: 14, training loss: 416.790563789662, train time: 112.20634722709656
epoch: 15, training loss: 415.96645587601233, train time: 111.61615204811096
epoch: 16, training loss: 416.9239719483885, train time: 111.9439308643341
epoch: 17, training loss: 417.1954511096119, train time: 110.90878987312317
epoch: 18, training loss: 417.10129496324225, train time: 112.75140953063965
epoch: 19, training loss: 419.2136213077174, train time: 110.27193665504456
epoch: 20, training loss: 419.09660612166044, train time: 111.69370913505554
epoch: 21, training loss: 418.59427907821373, train time: 110.09411764144897
epoch: 22, training loss: 419.36177385793417, train time: 109.15642738342285
epoch: 23, training loss: 420.7089483473683, train time: 108.35713410377502
epoch: 24, training loss: 419.23887082058354, train time: 110.34282088279724
epoch: 25, training loss: 419.50051350027206, train time: 109.9108624458313
epoch: 26, training loss: 420.7939903133665, train time: 110.1051549911499
epoch: 27, training loss: 421.3346650446183, train time: 109.20150756835938
epoch: 28, training loss: 421.37527303848765, train time: 109.00465226173401
epoch: 29, training loss: 421.3079075992864, train time: 108.2510416507721
epoch: 30, training loss: 421.4655143133423, train time: 109.073326587677
epoch: 31, training loss: 421.41936485582846, train time: 108.2506217956543
epoch: 32, training loss: 421.10865236935206, train time: 108.8777825832367
epoch: 33, training loss: 420.95036148434156, train time: 109.54846692085266
epoch: 34, training loss: 421.0122723405657, train time: 110.24249124526978
epoch: 35, training loss: 420.94578046922106, train time: 110.877845287323
epoch: 36, training loss: 421.43405088735744, train time: 109.80702924728394
epoch: 37, training loss: 421.04399127245415, train time: 110.08106851577759
epoch: 38, training loss: 420.88301303153276, train time: 109.25696182250977
epoch: 39, training loss: 421.2137629192148, train time: 109.47886109352112
epoch: 40, training loss: 421.44352577463724, train time: 110.2235734462738
epoch: 41, training loss: 421.8022491231677, train time: 110.3399109840393
epoch: 42, training loss: 421.2438352184836, train time: 109.58782887458801
epoch: 43, training loss: 421.2185326445033, train time: 110.3374993801117
epoch: 44, training loss: 420.6160644927877, train time: 108.72105073928833
epoch: 45, training loss: 420.92372244992293, train time: 109.22615623474121
epoch: 46, training loss: 421.02190847930615, train time: 109.53689956665039
epoch: 47, training loss: 420.9536695225106, train time: 109.02614450454712
epoch: 48, training loss: 420.8583547399612, train time: 109.97601270675659
epoch: 49, training loss: 420.9094089414866, train time: 110.59532427787781
Traceback (most recent call last):
  File "/home/ubuntu/model/PaperModel/model/recommendation_model.py", line 417, in <module>
    rec_net(train_loader, test_loader, node_emb, sequence_tensor)
  File "/home/ubuntu/model/PaperModel/model/recommendation_model.py", line 179, in rec_net
    normalized_scores = [((u_i_score - min(scores)) / (max(scores) - min(scores))) for u_i_score in scores]
  File "/home/ubuntu/model/PaperModel/model/recommendation_model.py", line 179, in <listcomp>
    normalized_scores = [((u_i_score - min(scores)) / (max(scores) - min(scores))) for u_i_score in scores]
ZeroDivisionError: float division by zero
